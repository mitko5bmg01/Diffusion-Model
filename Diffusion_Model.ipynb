{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zeLDjY7fqqQ8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img * 0.5 + 0.5\n",
        "    img = img.squeeze(0)\n",
        "    npimg = img.clip(0,1).detach().cpu().numpy().transpose(1, 2, 0)\n",
        "    npimg -= npimg.min(); npimg /= npimg.max()\n",
        "    plt.imshow(npimg)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9gXmuP7Wuez4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.down_layers = torch.nn.ModuleList([\n",
        "            nn.Conv2d(3, 32, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
        "        ])\n",
        "        self.up_layers = torch.nn.ModuleList([\n",
        "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(128, 32, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
        "        ])\n",
        "        self.final_conv1 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.final_conv2 = nn.Conv2d(16, 3, kernel_size=3, padding=1)\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.downscale = nn.MaxPool2d(2)\n",
        "        self.upscale = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "\n",
        "        for i, layer in enumerate(self.down_layers):\n",
        "            x = self.act(layer(x))\n",
        "            if i < 2:\n",
        "                skips.append(x)\n",
        "                x = self.downscale(x)\n",
        "\n",
        "        for i, layer in enumerate(self.up_layers):\n",
        "            if i > 0:\n",
        "                x = self.upscale(x)\n",
        "                x = torch.concatenate( [x, skips.pop()], axis=1)\n",
        "            x = self.act(layer(x))\n",
        "\n",
        "        x = self.act(self.final_conv1(x))\n",
        "        x = self.final_conv2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZfAaZYpPNWLF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionParameters(nn.Module):\n",
        "    def __init__(self, beta_0, beta_T, T, device):\n",
        "        super(DiffusionParameters, self).__init__()\n",
        "\n",
        "        self.betas = torch.linspace(beta_0, beta_T, T+1, device=device)\n",
        "        self.sqrt_betas = torch.sqrt(self.betas)\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_bar = torch.cumprod(self.alphas, dim=0).to(device)\n",
        "        self.one_minus_alphas_bar = 1.0 - self.alphas_bar\n",
        "        self.sqrt_one_minus_alphas_bar = torch.sqrt(self.one_minus_alphas_bar)\n",
        "        self.complex_mult = self.betas / self.sqrt_one_minus_alphas_bar\n",
        "        self.sqrt_alphas_bar = torch.sqrt(self.alphas_bar)\n",
        "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
        "        self.sqrt_alphas_inv = 1.0 / self.sqrt_alphas"
      ],
      "metadata": {
        "id": "o8rEWZfkGWm4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'batch_size': 128,\n",
        "    'num_epoch': 500,\n",
        "    'beta_0': 1e-4,\n",
        "    'beta_T': 0.02,\n",
        "    'T': 1000,\n",
        "    'lr': 1e-4\n",
        "}"
      ],
      "metadata": {
        "id": "Pdaaxhxyq_i9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_dataset_cats = Subset(train_dataset, np.where(np.array(train_dataset.targets) == 3)[0])\n",
        "train_loader = DataLoader(train_dataset_cats, batch_size=config['batch_size'], shuffle=True)\n",
        "\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_dataset_cats = Subset(test_dataset, np.where(np.array(test_dataset.targets) == 3)[0])\n",
        "test_loader = DataLoader(test_dataset_cats, batch_size=config['batch_size'], shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjIjsNoprrMc",
        "outputId": "11137009-479a-4787-f3fa-63c0da57e179"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43400612.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet().to(device)\n",
        "diffusion_params = DiffusionParameters(\n",
        "    config['beta_0'], config['beta_T'], config['T'], device\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000)\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "ErQdz_7XKeSE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_from_noise(model, diffusion_params, image_shape, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image_t = torch.randn((1,) + image_shape).to(device)\n",
        "\n",
        "        for t in range(config['T'], 0, -1):\n",
        "\n",
        "            image_t = diffusion_params.sqrt_alphas_inv[t] * (\n",
        "                image_t - diffusion_params.complex_mult[t] * model(image_t)\n",
        "            )\n",
        "\n",
        "            if t > 1:\n",
        "                noise = torch.randn(image_shape).to(device)\n",
        "                image_t += diffusion_params.sqrt_betas[t] * noise\n",
        "\n",
        "        imshow(image_t)"
      ],
      "metadata": {
        "id": "1seziBm0sSXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "for epoch in range(config['num_epoch']):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch, _ in tqdm(train_loader):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        noise = torch.randn(batch.shape).to(device)\n",
        "\n",
        "        timesteps = torch.randint(config['T'], (batch.shape[0], 1, 1, 1), device=device)\n",
        "\n",
        "        batch_with_noise = batch * diffusion_params.sqrt_alphas_bar[timesteps] + \\\n",
        "                           noise * diffusion_params.sqrt_one_minus_alphas_bar[timesteps]\n",
        "\n",
        "        output = model(batch_with_noise)\n",
        "        loss = torch.norm(output - noise, dim=1).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    lr_scheduler.step()\n",
        "    print(f'Epoch: {epoch}, Loss: {np.mean(losses)}')\n",
        "\n",
        "    if (epoch + 1) % 25 == 0:\n",
        "        model.eval()\n",
        "        sample_from_noise(model, diffusion_params, batch.shape[1:], device)"
      ],
      "metadata": {
        "id": "yVvr7b2zIF0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_from_noise(model, diffusion_params, (3, 32, 32), device)"
      ],
      "metadata": {
        "id": "T9UfrxcOt3J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQjG4swD_ds0"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}